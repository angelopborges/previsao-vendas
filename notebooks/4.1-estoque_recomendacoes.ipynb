{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos e contexto de dados carregados/reconstruídos para geração de previsões.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file_path = ''\n",
    "models_dir = 'models'\n",
    "\n",
    "best_xgb_model = None\n",
    "preprocessor = None\n",
    "features_to_use = []\n",
    "historical_weekly_avg = None\n",
    "unique_stores_depts_list = []\n",
    "df_stores_load = None\n",
    "last_historical_date = None\n",
    "\n",
    "try:\n",
    "    best_xgb_model = joblib.load(os.path.join(models_dir, 'best_xgb_model.joblib'))\n",
    "    preprocessor = joblib.load(os.path.join(models_dir, 'preprocessor.joblib'))\n",
    "\n",
    "    df_stores_load = pd.read_csv(os.path.join(file_path, 'data/raw/stores data-set.csv'))\n",
    "    df_features_load = pd.read_csv(os.path.join(file_path, 'data/raw/Features data set.csv'))\n",
    "    df_sales_load = pd.read_csv(os.path.join(file_path, 'data/raw/sales data-set.csv'))\n",
    "\n",
    "    df_sales_load['Date'] = pd.to_datetime(df_sales_load['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df_features_load['Date'] = pd.to_datetime(df_features_load['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df_sales_load.dropna(subset=['Date'], inplace=True)\n",
    "    df_features_load.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    df_sales_stores_load = pd.merge(df_sales_load, df_stores_load, on='Store', how='left')\n",
    "    df_final_for_context = pd.merge(df_sales_stores_load, df_features_load, on=['Store', 'Date'], how='left')\n",
    "\n",
    "    markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
    "    for col in markdown_cols:\n",
    "        if col in df_final_for_context.columns:\n",
    "            df_final_for_context[col] = df_final_for_context[col].fillna(0)\n",
    "\n",
    "    economic_cols = ['CPI', 'Unemployment']\n",
    "    for col in economic_cols:\n",
    "        if col in df_final_for_context.columns:\n",
    "            df_final_for_context[col] = df_final_for_context[col].interpolate(method='linear', limit_direction='both')\n",
    "            if df_final_for_context[col].isnull().any():\n",
    "                df_final_for_context[col] = df_final_for_context[col].fillna(df_final_for_context[col].mean())\n",
    "\n",
    "    df_final_for_context = df_final_for_context[df_final_for_context['Weekly_Sales'] > 0]\n",
    "    df_final_for_context['Date'] = pd.to_datetime(df_final_for_context['Date'], errors='coerce')\n",
    "    df_final_for_context.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    df_final_for_context['Year'] = df_final_for_context['Date'].dt.year\n",
    "    df_final_for_context['Month'] = df_final_for_context['Date'].dt.month\n",
    "    df_final_for_context['Week'] = df_final_for_context['Date'].dt.isocalendar().week.astype(int)\n",
    "    df_final_for_context['Day'] = df_final_for_context['Date'].dt.day\n",
    "    df_final_for_context['DayOfWeek'] = df_final_for_context['Date'].dt.dayofweek\n",
    "    df_final_for_context['DayOfYear'] = df_final_for_context['Date'].dt.dayofyear\n",
    "\n",
    "    if 'IsHoliday_x' in df_final_for_context.columns and 'IsHoliday_y' in df_final_for_context.columns:\n",
    "        df_final_for_context.rename(columns={'IsHoliday_x': 'IsHoliday'}, inplace=True)\n",
    "        df_final_for_context.drop(columns=['IsHoliday_y'], inplace=True)\n",
    "    elif 'IsHoliday_x' in df_final_for_context.columns:\n",
    "        df_final_for_context.rename(columns={'IsHoliday_x': 'IsHoliday'}, inplace=True)\n",
    "    elif 'IsHoliday_y' in df_final_for_context.columns:\n",
    "        df_final_for_context.rename(columns={'IsHoliday_y': 'IsHoliday'}, inplace=True)\n",
    "\n",
    "    if 'IsHoliday' in df_final_for_context.columns:\n",
    "        df_final_for_context['IsHoliday_Flag'] = df_final_for_context['IsHoliday'].astype(int)\n",
    "\n",
    "    df_final_for_context['SuperBowl'] = ((df_final_for_context['Month'] == 2) & (df_final_for_context['Week'].isin([6, 7])) | \\\n",
    "                                         (df_final_for_context['Month'] == 9) & (df_final_for_context['Week'].isin([36])) | \\\n",
    "                                         (df_final_for_context['Month'] == 11) & (df_final_for_context['Week'].isin([47])) | \\\n",
    "                                         (df_final_for_context['Month'] == 12) & (df_final_for_context['Week'].isin([51, 52]))).astype(int)\n",
    "    df_final_for_context['IsHoliday'] = df_final_for_context['IsHoliday_Flag'].astype(bool)\n",
    "\n",
    "    df_final_for_context['LaborDay'] = ((df_final_for_context['Month'] == 9) & (df_final_for_context['Week'].isin([36])) & (df_final_for_context['IsHoliday'] == True)).astype(int)\n",
    "    df_final_for_context['Thanksgiving'] = ((df_final_for_context['Month'] == 11) & (df_final_for_context['Week'].isin([47])) & (df_final_for_context['IsHoliday'] == True)).astype(int)\n",
    "    df_final_for_context['Christmas'] = ((df_final_for_context['Month'] == 12) & (df_final_for_context['Week'].isin([51, 52])) & (df_final_for_context['IsHoliday'] == True)).astype(int)\n",
    "\n",
    "    historical_weekly_avg = df_final_for_context.groupby('Week')[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].mean().reset_index()\n",
    "    unique_stores_depts_list = [tuple(x) for x in df_final_for_context[['Store', 'Dept']].drop_duplicates().values]\n",
    "    last_historical_date = df_final_for_context['Date'].max()\n",
    "\n",
    "    features_to_use = [\n",
    "        'Store', 'Dept', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
    "        'IsHoliday_Flag',\n",
    "        'Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'DayOfYear',\n",
    "        'SuperBowl', 'LaborDay', 'Thanksgiving', 'Christmas',\n",
    "        'TotalMarkDown', 'HasAnyMarkDown'\n",
    "    ]\n",
    "    markdown_cols_existing_in_df_final_context = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'] # Usar essa lista para preencher 'Has_MarkDownX' e 'MarkDownX'\n",
    "    for col in markdown_cols_existing_in_df_final_context:\n",
    "        if f'Has_{col}' not in features_to_use:\n",
    "             features_to_use.append(f'Has_{col}')\n",
    "        if col not in features_to_use:\n",
    "            features_to_use.append(col)\n",
    "    \n",
    "    if 'Type' in df_stores_load.columns and 'Type' not in features_to_use: # df_stores_load contém a coluna Type\n",
    "        features_to_use.append('Type')\n",
    "\n",
    "\n",
    "    print(\"Modelos e contexto de dados carregados/reconstruídos para geração de previsões.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro na preparação dos dados ou carregamento de modelos: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_future_predictions_df(num_weeks_to_predict=52):\n",
    "    \n",
    "    prediction_start_date = last_historical_date + timedelta(weeks=1)\n",
    "    prediction_end_date = prediction_start_date + timedelta(weeks=num_weeks_to_predict -1)\n",
    "\n",
    "    future_dates = pd.date_range(start=prediction_start_date, end=prediction_end_date, freq='W-FRI')\n",
    "\n",
    "    future_df = pd.DataFrame()\n",
    "    for store_id, dept_id in unique_stores_depts_list:\n",
    "        temp_df = pd.DataFrame({'Date': future_dates,\n",
    "                                'Store': store_id,\n",
    "                                'Dept': dept_id})\n",
    "        future_df = pd.concat([future_df, temp_df], ignore_index=True)\n",
    "\n",
    "    future_df['Year'] = future_df['Date'].dt.year\n",
    "    future_df['Month'] = future_df['Date'].dt.month\n",
    "    future_df['Week'] = future_df['Date'].dt.isocalendar().week.astype(int)\n",
    "    future_df['Day'] = future_df['Date'].dt.day\n",
    "    future_df['DayOfWeek'] = future_df['Date'].dt.dayofweek\n",
    "    future_df['DayOfYear'] = future_df['Date'].dt.dayofyear\n",
    "\n",
    "    future_df['IsHoliday'] = False\n",
    "    future_df['IsHoliday_Flag'] = ((future_df['Month'] == 2) & (future_df['Week'].isin([6, 7])) | \\\n",
    "                                    (future_df['Month'] == 9) & (future_df['Week'].isin([36])) | \\\n",
    "                                    (future_df['Month'] == 11) & (future_df['Week'].isin([47])) | \\\n",
    "                                    (future_df['Month'] == 12) & (future_df['Week'].isin([51, 52]))).astype(int)\n",
    "    future_df['IsHoliday'] = future_df['IsHoliday_Flag'].astype(bool)\n",
    "\n",
    "    future_df['SuperBowl'] = ((future_df['Month'] == 2) & (future_df['Week'].isin([6, 7])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "    future_df['LaborDay'] = ((future_df['Month'] == 9) & (future_df['Week'].isin([36])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "    future_df['Thanksgiving'] = ((future_df['Month'] == 11) & (future_df['Week'].isin([47])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "    future_df['Christmas'] = ((future_df['Month'] == 12) & (future_df['Week'].isin([51, 52])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "\n",
    "    future_df = pd.merge(future_df, historical_weekly_avg, on='Week', how='left')\n",
    "\n",
    "    for col in markdown_cols:\n",
    "        if col in features_to_use:\n",
    "            future_df[col] = 0.0\n",
    "        if f'Has_{col}' in features_to_use:\n",
    "            future_df[f'Has_{col}'] = 0\n",
    "    if 'TotalMarkDown' in features_to_use:\n",
    "        future_df['TotalMarkDown'] = 0.0\n",
    "    if 'HasAnyMarkDown' in features_to_use:\n",
    "        future_df['HasAnyMarkDown'] = 0\n",
    "\n",
    "    future_df = pd.merge(future_df, df_stores_load[['Store', 'Type', 'Size']].drop_duplicates(), on='Store', how='left')\n",
    "\n",
    "    if 'Type' in future_df.columns:\n",
    "        future_df['Type'] = future_df['Type'].astype('category')\n",
    "\n",
    "    future_X_raw = future_df[features_to_use]\n",
    "    X_future_processed = preprocessor.transform(future_X_raw)\n",
    "    if hasattr(X_future_processed, 'toarray'):\n",
    "        X_future_processed = X_future_processed.toarray()\n",
    "\n",
    "    future_predictions = best_xgb_model.predict(X_future_processed)\n",
    "    future_predictions[future_predictions < 0] = 0\n",
    "\n",
    "    df_future_predictions = future_df[['Store', 'Dept', 'Date']].copy()\n",
    "    df_future_predictions['Predicted_Weekly_Sales'] = future_predictions\n",
    "    \n",
    "    return df_future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Início do Módulo de Otimização de Estoque ===\n",
      "\n",
      "Gerando previsões futuras para o ano completo...\n",
      "DataFrame de previsões futuras gerado. Shape: (172796, 4)\n",
      "   Store  Dept       Date  Predicted_Weekly_Sales\n",
      "0      1     1 2012-11-02            36898.437500\n",
      "1      1     1 2012-11-09            16620.400391\n",
      "2      1     1 2012-11-16            17820.150391\n",
      "3      1     1 2012-11-23            20685.056641\n",
      "4      1     1 2012-11-30            25611.126953\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Início do Módulo de Otimização de Estoque ===\")\n",
    "\n",
    "print(\"\\nGerando previsões futuras para o ano completo...\")\n",
    "df_future_predictions = generate_future_predictions_df(num_weeks_to_predict=52)\n",
    "print(f\"DataFrame de previsões futuras gerado. Shape: {df_future_predictions.shape}\")\n",
    "print(df_future_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calculando a média de vendas previstas por Loja e Departamento\n",
    "average_sales_per_sd = df_future_predictions.groupby(['Store', 'Dept'])['Predicted_Weekly_Sales'].mean().reset_index()\n",
    "average_sales_per_sd.rename(columns={'Predicted_Weekly_Sales': 'Avg_Predicted_Weekly_Sales'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Médias de vendas previstas por Loja/Departamento calculadas.\n",
      "   Store  Dept       Date  Predicted_Weekly_Sales  Avg_Predicted_Weekly_Sales\n",
      "0      1     1 2012-11-02            36898.437500                23059.716797\n",
      "1      1     1 2012-11-09            16620.400391                23059.716797\n",
      "2      1     1 2012-11-16            17820.150391                23059.716797\n",
      "3      1     1 2012-11-23            20685.056641                23059.716797\n",
      "4      1     1 2012-11-30            25611.126953                23059.716797\n"
     ]
    }
   ],
   "source": [
    "#Merge de volta com o df_future_predictions\n",
    "df_future_predictions = pd.merge(df_future_predictions, average_sales_per_sd, on=['Store', 'Dept'], how='left')\n",
    "\n",
    "print(\"\\nMédias de vendas previstas por Loja/Departamento calculadas.\")\n",
    "print(df_future_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando Lógica de Recomendação de Estoque\n",
    "\n",
    "THRESHOLD_INCREASE = 0.20 # 20% acima da média para recomendar aumento\n",
    "THRESHOLD_DECREASE = 0.15 # 15% abaixo da média para recomendar redução\n",
    "\n",
    "def get_stock_recommendation(row):\n",
    "    predicted = row['Predicted_Weekly_Sales']\n",
    "    avg = row['Avg_Predicted_Weekly_Sales']\n",
    "\n",
    "    if predicted > avg * (1 + THRESHOLD_INCREASE):\n",
    "        return 'Aumentar Estoque'\n",
    "    elif predicted < avg * (1 - THRESHOLD_DECREASE):\n",
    "        return 'Reduzir Estoque'\n",
    "    else:\n",
    "        return 'Manter Estoque'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recomendações de estoque geradas (amostra):\n",
      "   Store  Dept       Date  Predicted_Weekly_Sales  Avg_Predicted_Weekly_Sales  \\\n",
      "0      1     1 2012-11-02            36898.437500                23059.716797   \n",
      "1      1     1 2012-11-09            16620.400391                23059.716797   \n",
      "2      1     1 2012-11-16            17820.150391                23059.716797   \n",
      "3      1     1 2012-11-23            20685.056641                23059.716797   \n",
      "4      1     1 2012-11-30            25611.126953                23059.716797   \n",
      "5      1     1 2012-12-07            23989.419922                23059.716797   \n",
      "6      1     1 2012-12-14            37208.308594                23059.716797   \n",
      "7      1     1 2012-12-21            41732.515625                23059.716797   \n",
      "8      1     1 2012-12-28            30802.324219                23059.716797   \n",
      "9      1     1 2013-01-04            16351.446289                23059.716797   \n",
      "\n",
      "  Stock_Recommendation  \n",
      "0     Aumentar Estoque  \n",
      "1      Reduzir Estoque  \n",
      "2      Reduzir Estoque  \n",
      "3       Manter Estoque  \n",
      "4       Manter Estoque  \n",
      "5       Manter Estoque  \n",
      "6     Aumentar Estoque  \n",
      "7     Aumentar Estoque  \n",
      "8     Aumentar Estoque  \n",
      "9      Reduzir Estoque  \n",
      "\n",
      "=== Resumo das Recomendações de Estoque ===\n",
      "Contagem de Recomendações:\n",
      "Stock_Recommendation\n",
      "Manter Estoque      100216\n",
      "Reduzir Estoque      51693\n",
      "Aumentar Estoque     20887\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 Semanas/Loja/Departamento para 'Aumentar Estoque' (maior desvio):\n",
      "        Store  Dept       Date  Predicted_Weekly_Sales  Deviation_from_Avg\n",
      "21847       6    47 2012-12-21             1184.468140           51.000004\n",
      "125795     32    77 2012-12-21              917.003784           51.000004\n",
      "34431       9    77 2012-12-21                0.219880           51.000004\n",
      "97767      25    47 2012-12-21              404.786743           51.000000\n",
      "109883     28    51 2012-12-21              189.634506           51.000000\n",
      "167136     44    28 2012-12-28              779.242065           51.000000\n",
      "167084     44    27 2012-12-28              273.001770           51.000000\n",
      "128760     33    52 2012-12-28              230.587341           51.000000\n",
      "127356     33    12 2012-12-28              276.459045           51.000000\n",
      "97975      25    51 2012-12-21             1591.339355           51.000000\n",
      "\n",
      "Top 10 Semanas/Loja/Departamento para 'Reduzir Estoque' (maior desvio):\n",
      "        Store  Dept       Date  Predicted_Weekly_Sales  Deviation_from_Avg\n",
      "172756     45    98 2013-01-25                     0.0                 1.0\n",
      "89929      23    51 2013-03-29                     0.0                 1.0\n",
      "172176     45    83 2012-11-30                     0.0                 1.0\n",
      "172183     45    83 2013-01-18                     0.0                 1.0\n",
      "172184     45    83 2013-01-25                     0.0                 1.0\n",
      "89938      23    51 2013-05-31                     0.0                 1.0\n",
      "89912      23    51 2012-11-30                     0.0                 1.0\n",
      "119707     31    19 2012-11-23                     0.0                 1.0\n",
      "119706     31    19 2012-11-16                     0.0                 1.0\n",
      "119705     31    19 2012-11-09                     0.0                 1.0\n",
      "\n",
      "=== Módulo de Otimização de Estoque Concluído ===\n"
     ]
    }
   ],
   "source": [
    "df_future_predictions['Stock_Recommendation'] = df_future_predictions.apply(get_stock_recommendation, axis=1)\n",
    "\n",
    "print(\"\\nRecomendações de estoque geradas (amostra):\")\n",
    "print(df_future_predictions[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales', 'Avg_Predicted_Weekly_Sales', 'Stock_Recommendation']].head(10))\n",
    "\n",
    "#Relatório/Insights (Resumo das Recomendações)\n",
    "print(\"\\n=== Resumo das Recomendações de Estoque ===\")\n",
    "print(\"Contagem de Recomendações:\")\n",
    "print(df_future_predictions['Stock_Recommendation'].value_counts())\n",
    "\n",
    "print(\"\\nTop 10 Semanas/Loja/Departamento para 'Aumentar Estoque' (maior desvio):\")\n",
    "top_increase_rec = df_future_predictions[df_future_predictions['Stock_Recommendation'] == 'Aumentar Estoque'].copy()\n",
    "top_increase_rec['Deviation_from_Avg'] = (top_increase_rec['Predicted_Weekly_Sales'] / top_increase_rec['Avg_Predicted_Weekly_Sales']) - 1\n",
    "print(top_increase_rec.sort_values(by='Deviation_from_Avg', ascending=False).head(10)[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales', 'Deviation_from_Avg']])\n",
    "\n",
    "print(\"\\nTop 10 Semanas/Loja/Departamento para 'Reduzir Estoque' (maior desvio):\")\n",
    "top_decrease_rec = df_future_predictions[df_future_predictions['Stock_Recommendation'] == 'Reduzir Estoque'].copy()\n",
    "top_decrease_rec['Deviation_from_Avg'] = 1 - (top_decrease_rec['Predicted_Weekly_Sales'] / top_decrease_rec['Avg_Predicted_Weekly_Sales'])\n",
    "print(top_decrease_rec.sort_values(by='Deviation_from_Avg', ascending=False).head(10)[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales', 'Deviation_from_Avg']])\n",
    "\n",
    "print(\"\\n=== Módulo de Otimização de Estoque Concluído ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
