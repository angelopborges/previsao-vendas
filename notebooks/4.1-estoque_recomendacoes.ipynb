{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos e contexto de dados carregados/reconstruídos para geração de previsões.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file_path = ''\n",
    "models_dir = 'models'\n",
    "\n",
    "best_xgb_model = None\n",
    "preprocessor = None\n",
    "features_to_use = []\n",
    "historical_weekly_avg = None\n",
    "unique_stores_depts_list = []\n",
    "df_stores_load = None\n",
    "last_historical_date = None\n",
    "\n",
    "try:\n",
    "    best_xgb_model = joblib.load(os.path.join(models_dir, 'best_xgb_model.joblib'))\n",
    "    preprocessor = joblib.load(os.path.join(models_dir, 'preprocessor.joblib'))\n",
    "\n",
    "    df_stores_load = pd.read_csv(os.path.join(file_path, 'data/raw/stores data-set.csv'))\n",
    "    df_features_load = pd.read_csv(os.path.join(file_path, 'data/raw/Features data set.csv'))\n",
    "    df_sales_load = pd.read_csv(os.path.join(file_path, 'data/raw/sales data-set.csv'))\n",
    "\n",
    "    df_sales_load['Date'] = pd.to_datetime(df_sales_load['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df_features_load['Date'] = pd.to_datetime(df_features_load['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "    df_sales_load.dropna(subset=['Date'], inplace=True)\n",
    "    df_features_load.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    df_sales_stores_load = pd.merge(df_sales_load, df_stores_load, on='Store', how='left')\n",
    "    df_final_for_context = pd.merge(df_sales_stores_load, df_features_load, on=['Store', 'Date'], how='left')\n",
    "\n",
    "    markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
    "    for col in markdown_cols:\n",
    "        if col in df_final_for_context.columns:\n",
    "            df_final_for_context[col] = df_final_for_context[col].fillna(0)\n",
    "\n",
    "    economic_cols = ['CPI', 'Unemployment']\n",
    "    for col in economic_cols:\n",
    "        if col in df_final_for_context.columns:\n",
    "            df_final_for_context[col] = df_final_for_context[col].interpolate(method='linear', limit_direction='both')\n",
    "            if df_final_for_context[col].isnull().any():\n",
    "                df_final_for_context[col] = df_final_for_context[col].fillna(df_final_for_context[col].mean())\n",
    "\n",
    "    df_final_for_context = df_final_for_context[df_final_for_context['Weekly_Sales'] > 0]\n",
    "    df_final_for_context['Date'] = pd.to_datetime(df_final_for_context['Date'], errors='coerce')\n",
    "    df_final_for_context.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "    df_final_for_context['Year'] = df_final_for_context['Date'].dt.year\n",
    "    df_final_for_context['Month'] = df_final_for_context['Date'].dt.month\n",
    "    df_final_for_context['Week'] = df_final_for_context['Date'].dt.isocalendar().week.astype(int)\n",
    "    df_final_for_context['Day'] = df_final_for_context['Date'].dt.day\n",
    "    df_final_for_context['DayOfWeek'] = df_final_for_context['Date'].dt.dayofweek\n",
    "    df_final_for_context['DayOfYear'] = df_final_for_context['Date'].dt.dayofyear\n",
    "\n",
    "    if 'IsHoliday_x' in df_final_for_context.columns and 'IsHoliday_y' in df_final_for_context.columns:\n",
    "        df_final_for_context.rename(columns={'IsHoliday_x': 'IsHoliday'}, inplace=True)\n",
    "        df_final_for_context.drop(columns=['IsHoliday_y'], inplace=True)\n",
    "    elif 'IsHoliday_x' in df_final_for_context.columns:\n",
    "        df_final_for_context.rename(columns={'IsHoliday_x': 'IsHoliday'}, inplace=True)\n",
    "    elif 'IsHoliday_y' in df_final_for_context.columns:\n",
    "        df_final_for_context.rename(columns={'IsHoliday_y': 'IsHoliday'}, inplace=True)\n",
    "\n",
    "    if 'IsHoliday' in df_final_for_context.columns:\n",
    "        df_final_for_context['IsHoliday_Flag'] = df_final_for_context['IsHoliday'].astype(int)\n",
    "\n",
    "    df_final_for_context['SuperBowl'] = ((df_final_for_context['Month'] == 2) & (df_final_for_context['Week'].isin([6, 7])) | \\\n",
    "                                         (df_final_for_context['Month'] == 9) & (df_final_for_context['Week'].isin([36])) | \\\n",
    "                                         (df_final_for_context['Month'] == 11) & (df_final_for_context['Week'].isin([47])) | \\\n",
    "                                         (df_final_for_context['Month'] == 12) & (df_final_for_context['Week'].isin([51, 52]))).astype(int)\n",
    "    df_final_for_context['IsHoliday'] = df_final_for_context['IsHoliday_Flag'].astype(bool)\n",
    "\n",
    "    df_final_for_context['LaborDay'] = ((df_final_for_context['Month'] == 9) & (df_final_for_context['Week'].isin([36])) & (df_final_for_context['IsHoliday'] == True)).astype(int)\n",
    "    df_final_for_context['Thanksgiving'] = ((df_final_for_context['Month'] == 11) & (df_final_for_context['Week'].isin([47])) & (df_final_for_context['IsHoliday'] == True)).astype(int)\n",
    "    df_final_for_context['Christmas'] = ((df_final_for_context['Month'] == 12) & (df_final_for_context['Week'].isin([51, 52])) & (df_final_for_context['IsHoliday'] == True)).astype(int)\n",
    "\n",
    "    historical_weekly_avg = df_final_for_context.groupby('Week')[['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']].mean().reset_index()\n",
    "    unique_stores_depts_list = [tuple(x) for x in df_final_for_context[['Store', 'Dept']].drop_duplicates().values]\n",
    "    last_historical_date = df_final_for_context['Date'].max()\n",
    "\n",
    "    features_to_use = [\n",
    "        'Store', 'Dept', 'Size', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
    "        'IsHoliday_Flag',\n",
    "        'Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'DayOfYear',\n",
    "        'SuperBowl', 'LaborDay', 'Thanksgiving', 'Christmas',\n",
    "        'TotalMarkDown', 'HasAnyMarkDown'\n",
    "    ]\n",
    "    markdown_cols_existing_in_df_final_context = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'] # Usar essa lista para preencher 'Has_MarkDownX' e 'MarkDownX'\n",
    "    for col in markdown_cols_existing_in_df_final_context:\n",
    "        if f'Has_{col}' not in features_to_use:\n",
    "             features_to_use.append(f'Has_{col}')\n",
    "        if col not in features_to_use:\n",
    "            features_to_use.append(col)\n",
    "    \n",
    "    if 'Type' in df_stores_load.columns and 'Type' not in features_to_use: # df_stores_load contém a coluna Type\n",
    "        features_to_use.append('Type')\n",
    "\n",
    "\n",
    "    print(\"Modelos e contexto de dados carregados/reconstruídos para geração de previsões.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro na preparação dos dados ou carregamento de modelos: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_future_predictions_df(num_weeks_to_predict=52):\n",
    "    \n",
    "    prediction_start_date = last_historical_date + timedelta(weeks=1)\n",
    "    prediction_end_date = prediction_start_date + timedelta(weeks=num_weeks_to_predict -1)\n",
    "\n",
    "    future_dates = pd.date_range(start=prediction_start_date, end=prediction_end_date, freq='W-FRI')\n",
    "\n",
    "    future_df = pd.DataFrame()\n",
    "    for store_id, dept_id in unique_stores_depts_list:\n",
    "        temp_df = pd.DataFrame({'Date': future_dates,\n",
    "                                'Store': store_id,\n",
    "                                'Dept': dept_id})\n",
    "        future_df = pd.concat([future_df, temp_df], ignore_index=True)\n",
    "\n",
    "    future_df['Year'] = future_df['Date'].dt.year\n",
    "    future_df['Month'] = future_df['Date'].dt.month\n",
    "    future_df['Week'] = future_df['Date'].dt.isocalendar().week.astype(int)\n",
    "    future_df['Day'] = future_df['Date'].dt.day\n",
    "    future_df['DayOfWeek'] = future_df['Date'].dt.dayofweek\n",
    "    future_df['DayOfYear'] = future_df['Date'].dt.dayofyear\n",
    "\n",
    "    future_df['IsHoliday'] = False\n",
    "    future_df['IsHoliday_Flag'] = ((future_df['Month'] == 2) & (future_df['Week'].isin([6, 7])) | \\\n",
    "                                    (future_df['Month'] == 9) & (future_df['Week'].isin([36])) | \\\n",
    "                                    (future_df['Month'] == 11) & (future_df['Week'].isin([47])) | \\\n",
    "                                    (future_df['Month'] == 12) & (future_df['Week'].isin([51, 52]))).astype(int)\n",
    "    future_df['IsHoliday'] = future_df['IsHoliday_Flag'].astype(bool)\n",
    "\n",
    "    future_df['SuperBowl'] = ((future_df['Month'] == 2) & (future_df['Week'].isin([6, 7])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "    future_df['LaborDay'] = ((future_df['Month'] == 9) & (future_df['Week'].isin([36])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "    future_df['Thanksgiving'] = ((future_df['Month'] == 11) & (future_df['Week'].isin([47])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "    future_df['Christmas'] = ((future_df['Month'] == 12) & (future_df['Week'].isin([51, 52])) & (future_df['IsHoliday'] == True)).astype(int)\n",
    "\n",
    "    future_df = pd.merge(future_df, historical_weekly_avg, on='Week', how='left')\n",
    "\n",
    "    for col in markdown_cols:\n",
    "        if col in features_to_use:\n",
    "            future_df[col] = 0.0\n",
    "        if f'Has_{col}' in features_to_use:\n",
    "            future_df[f'Has_{col}'] = 0\n",
    "    if 'TotalMarkDown' in features_to_use:\n",
    "        future_df['TotalMarkDown'] = 0.0\n",
    "    if 'HasAnyMarkDown' in features_to_use:\n",
    "        future_df['HasAnyMarkDown'] = 0\n",
    "\n",
    "    future_df = pd.merge(future_df, df_stores_load[['Store', 'Type', 'Size']].drop_duplicates(), on='Store', how='left')\n",
    "\n",
    "    if 'Type' in future_df.columns:\n",
    "        future_df['Type'] = future_df['Type'].astype('category')\n",
    "\n",
    "    future_X_raw = future_df[features_to_use]\n",
    "    X_future_processed = preprocessor.transform(future_X_raw)\n",
    "    if hasattr(X_future_processed, 'toarray'):\n",
    "        X_future_processed = X_future_processed.toarray()\n",
    "\n",
    "    future_predictions = best_xgb_model.predict(X_future_processed)\n",
    "    future_predictions[future_predictions < 0] = 0\n",
    "\n",
    "    df_future_predictions = future_df[['Store', 'Dept', 'Date']].copy()\n",
    "    df_future_predictions['Predicted_Weekly_Sales'] = future_predictions\n",
    "    \n",
    "    return df_future_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Início do Módulo de Otimização de Estoque ===\n",
      "\n",
      "Gerando previsões futuras para o ano completo...\n",
      "DataFrame de previsões futuras gerado. Shape: (172796, 4)\n",
      "   Store  Dept       Date  Predicted_Weekly_Sales\n",
      "0      1     1 2012-11-02            38940.558594\n",
      "1      1     1 2012-11-09            33469.152344\n",
      "2      1     1 2012-11-16            33011.730469\n",
      "3      1     1 2012-11-23            40626.339844\n",
      "4      1     1 2012-11-30            34499.335938\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Início do Módulo de Otimização de Estoque ===\")\n",
    "\n",
    "print(\"\\nGerando previsões futuras para o ano completo...\")\n",
    "df_future_predictions = generate_future_predictions_df(num_weeks_to_predict=52)\n",
    "print(f\"DataFrame de previsões futuras gerado. Shape: {df_future_predictions.shape}\")\n",
    "print(df_future_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calculando a média de vendas previstas por Loja e Departamento\n",
    "average_sales_per_sd = df_future_predictions.groupby(['Store', 'Dept'])['Predicted_Weekly_Sales'].mean().reset_index()\n",
    "average_sales_per_sd.rename(columns={'Predicted_Weekly_Sales': 'Avg_Predicted_Weekly_Sales'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Médias de vendas previstas por Loja/Departamento calculadas.\n",
      "   Store  Dept       Date  Predicted_Weekly_Sales  Avg_Predicted_Weekly_Sales\n",
      "0      1     1 2012-11-02            38940.558594                23797.998047\n",
      "1      1     1 2012-11-09            33469.152344                23797.998047\n",
      "2      1     1 2012-11-16            33011.730469                23797.998047\n",
      "3      1     1 2012-11-23            40626.339844                23797.998047\n",
      "4      1     1 2012-11-30            34499.335938                23797.998047\n"
     ]
    }
   ],
   "source": [
    "#Merge de volta com o df_future_predictions\n",
    "df_future_predictions = pd.merge(df_future_predictions, average_sales_per_sd, on=['Store', 'Dept'], how='left')\n",
    "\n",
    "print(\"\\nMédias de vendas previstas por Loja/Departamento calculadas.\")\n",
    "print(df_future_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando Lógica de Recomendação de Estoque\n",
    "\n",
    "THRESHOLD_INCREASE = 0.20 # 20% acima da média para recomendar aumento\n",
    "THRESHOLD_DECREASE = 0.15 # 15% abaixo da média para recomendar redução\n",
    "\n",
    "def get_stock_recommendation(row):\n",
    "    predicted = row['Predicted_Weekly_Sales']\n",
    "    avg = row['Avg_Predicted_Weekly_Sales']\n",
    "\n",
    "    if predicted > avg * (1 + THRESHOLD_INCREASE):\n",
    "        return 'Aumentar Estoque'\n",
    "    elif predicted < avg * (1 - THRESHOLD_DECREASE):\n",
    "        return 'Reduzir Estoque'\n",
    "    else:\n",
    "        return 'Manter Estoque'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recomendações de estoque geradas (amostra):\n",
      "   Store  Dept       Date  Predicted_Weekly_Sales  Avg_Predicted_Weekly_Sales  \\\n",
      "0      1     1 2012-11-02            38940.558594                23797.998047   \n",
      "1      1     1 2012-11-09            33469.152344                23797.998047   \n",
      "2      1     1 2012-11-16            33011.730469                23797.998047   \n",
      "3      1     1 2012-11-23            40626.339844                23797.998047   \n",
      "4      1     1 2012-11-30            34499.335938                23797.998047   \n",
      "5      1     1 2012-12-07            32422.630859                23797.998047   \n",
      "6      1     1 2012-12-14            41832.535156                23797.998047   \n",
      "7      1     1 2012-12-21            39307.824219                23797.998047   \n",
      "8      1     1 2012-12-28            34917.402344                23797.998047   \n",
      "9      1     1 2013-01-04            20377.414062                23797.998047   \n",
      "\n",
      "  Stock_Recommendation  \n",
      "0     Aumentar Estoque  \n",
      "1     Aumentar Estoque  \n",
      "2     Aumentar Estoque  \n",
      "3     Aumentar Estoque  \n",
      "4     Aumentar Estoque  \n",
      "5     Aumentar Estoque  \n",
      "6     Aumentar Estoque  \n",
      "7     Aumentar Estoque  \n",
      "8     Aumentar Estoque  \n",
      "9       Manter Estoque  \n",
      "\n",
      "=== Resumo das Recomendações de Estoque ===\n",
      "Contagem de Recomendações:\n",
      "Stock_Recommendation\n",
      "Manter Estoque      119637\n",
      "Reduzir Estoque      34260\n",
      "Aumentar Estoque     18899\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 Semanas/Loja/Departamento para 'Aumentar Estoque' (maior desvio):\n",
      "        Store  Dept       Date  Predicted_Weekly_Sales  Deviation_from_Avg\n",
      "82081      21    54 2013-04-26                2.784639           51.000000\n",
      "127719     33    21 2012-12-21               78.635178           51.000000\n",
      "139584     36    42 2013-02-22                8.276617           51.000000\n",
      "41715      11    50 2013-01-18               69.266586           51.000000\n",
      "33311       9    36 2013-06-07              136.962387           51.000000\n",
      "145919     38    35 2012-12-21                6.722505           51.000000\n",
      "94320      24    60 2013-09-06              264.889099           51.000000\n",
      "116851     30    28 2012-12-21               12.344975           51.000000\n",
      "25726       7    45 2013-07-26               42.481342           51.000000\n",
      "85920      22    51 2013-02-22               70.301666           50.999996\n",
      "\n",
      "Top 10 Semanas/Loja/Departamento para 'Reduzir Estoque' (maior desvio):\n",
      "        Store  Dept       Date  Predicted_Weekly_Sales  Deviation_from_Avg\n",
      "172793     45    98 2013-10-11                     0.0                 1.0\n",
      "100341     26    18 2013-06-21                     0.0                 1.0\n",
      "100342     26    18 2013-06-28                     0.0                 1.0\n",
      "100343     26    18 2013-07-05                     0.0                 1.0\n",
      "100344     26    18 2013-07-12                     0.0                 1.0\n",
      "100345     26    18 2013-07-19                     0.0                 1.0\n",
      "100346     26    18 2013-07-26                     0.0                 1.0\n",
      "100347     26    18 2013-08-02                     0.0                 1.0\n",
      "100348     26    18 2013-08-09                     0.0                 1.0\n",
      "100349     26    18 2013-08-16                     0.0                 1.0\n",
      "\n",
      "=== Módulo de Otimização de Estoque Concluído ===\n"
     ]
    }
   ],
   "source": [
    "df_future_predictions['Stock_Recommendation'] = df_future_predictions.apply(get_stock_recommendation, axis=1)\n",
    "\n",
    "print(\"\\nRecomendações de estoque geradas (amostra):\")\n",
    "print(df_future_predictions[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales', 'Avg_Predicted_Weekly_Sales', 'Stock_Recommendation']].head(10))\n",
    "\n",
    "#Relatório/Insights (Resumo das Recomendações)\n",
    "print(\"\\n=== Resumo das Recomendações de Estoque ===\")\n",
    "print(\"Contagem de Recomendações:\")\n",
    "print(df_future_predictions['Stock_Recommendation'].value_counts())\n",
    "\n",
    "print(\"\\nTop 10 Semanas/Loja/Departamento para 'Aumentar Estoque' (maior desvio):\")\n",
    "top_increase_rec = df_future_predictions[df_future_predictions['Stock_Recommendation'] == 'Aumentar Estoque'].copy()\n",
    "top_increase_rec['Deviation_from_Avg'] = (top_increase_rec['Predicted_Weekly_Sales'] / top_increase_rec['Avg_Predicted_Weekly_Sales']) - 1\n",
    "print(top_increase_rec.sort_values(by='Deviation_from_Avg', ascending=False).head(10)[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales', 'Deviation_from_Avg']])\n",
    "\n",
    "print(\"\\nTop 10 Semanas/Loja/Departamento para 'Reduzir Estoque' (maior desvio):\")\n",
    "top_decrease_rec = df_future_predictions[df_future_predictions['Stock_Recommendation'] == 'Reduzir Estoque'].copy()\n",
    "top_decrease_rec['Deviation_from_Avg'] = 1 - (top_decrease_rec['Predicted_Weekly_Sales'] / top_decrease_rec['Avg_Predicted_Weekly_Sales'])\n",
    "print(top_decrease_rec.sort_values(by='Deviation_from_Avg', ascending=False).head(10)[['Store', 'Dept', 'Date', 'Predicted_Weekly_Sales', 'Deviation_from_Avg']])\n",
    "\n",
    "print(\"\\n=== Módulo de Otimização de Estoque Concluído ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
